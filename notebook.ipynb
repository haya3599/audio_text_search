# =========================
# Option 2: Audio+Text Search with Phoneme 3-grams
# =========================

# --- Install/Imports ---
import re
import math
from collections import Counter, defaultdict

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import nltk
nltk.download('cmudict', quiet=True)
from nltk.corpus import cmudict

CMU = cmudict.dict()


# -------------------------
# Utilities
# -------------------------
def normalize_text(text: str) -> list[str]:
    """
    Lowercase + keep letters/spaces only + split to tokens.
    """
    text = text.lower()
    text = re.sub(r"[^a-z\s']", " ", text)
    tokens = [t for t in text.split() if t.strip()]
    return tokens

def word_to_phonemes(word: str) -> list[str]:
    """
    Map a word to a phoneme sequence using CMUdict.
    If word isn't in CMUdict, fall back to a simple heuristic (letters as pseudo-phonemes).
    We also strip stress digits (e.g., AH0 -> AH).
    """
    w = word.lower()
    if w in CMU:
        # take first pronunciation variant
        phones = CMU[w][0]
        phones = [re.sub(r"\d", "", p) for p in phones]  # remove stress digits
        return phones

    # fallback: simple character-based pseudo-phonemes (keeps pipeline robust)
    # This is acceptable as a fallback, but for best results choose words that exist in CMUdict.
    return list(w)

def text_to_phoneme_stream(text: str) -> list[str]:
    tokens = normalize_text(text)
    stream = []
    for token in tokens:
        stream.extend(word_to_phonemes(token))
    return stream

def make_phoneme_ngrams(phoneme_stream: list[str], n: int = 3) -> list[str]:
    """
    Return list of n-grams as joined strings, e.g. "S P IY"
    """
    grams = []
    if len(phoneme_stream) < n:
        return grams
    for i in range(len(phoneme_stream) - n + 1):
        grams.append(" ".join(phoneme_stream[i:i+n]))
    return grams

def build_tf_vector(ngrams: list[str]) -> Counter:
    return Counter(ngrams)

def cosine_similarity_counter(a: Counter, b: Counter) -> float:
    """
    Cosine similarity between two sparse vectors stored as Counters.
    """
    if not a or not b:
        return 0.0

    # dot product
    dot = 0.0
    # iterate over smaller
    if len(a) > len(b):
        a, b = b, a
    for k, va in a.items():
        vb = b.get(k, 0)
        dot += va * vb

    norm_a = math.sqrt(sum(v*v for v in a.values()))
    norm_b = math.sqrt(sum(v*v for v in b.values()))
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return float(dot / (norm_a * norm_b))


# -------------------------
# A.1 Create documents (2 text + 2 ASR)
# -------------------------
doc1_text = "the system detects speech errors in noisy environments"
doc2_text = "audio processing improves speech recognition accuracy"

# -------------------------
# A.2 ASR files with realistic-ish errors (especially in query words)
#    - diversify errors: different words corrupted in different ASR docs
# -------------------------
asr1_text = "the system detects speach erors in noisy environments"
asr2_text = "audio procesing improves speech recognition acuracy"

documents = {
    "doc1": doc1_text,
    "doc2": doc2_text,
    "asr1": asr1_text,
    "asr2": asr2_text,
}

# Show original documents
print("=== Documents ===")
for name, txt in documents.items():
    print(f"{name}: {txt}")

# -------------------------
# A.3 Query (clean, 3-4 words)
# -------------------------
query = "speech recognition accuracy"
print("\n=== Query ===")
print(query)


# -------------------------
# B. Build phoneme-3gram index (TF vectors)
# -------------------------
N = 3

doc_phoneme_streams = {}
doc_ngrams = {}
doc_vectors = {}

for name, txt in documents.items():
    stream = text_to_phoneme_stream(txt)
    grams = make_phoneme_ngrams(stream, n=N)
    vec = build_tf_vector(grams)

    doc_phoneme_streams[name] = stream
    doc_ngrams[name] = grams
    doc_vectors[name] = vec

# -------------------------
# C. Query to phoneme-3grams
# -------------------------
query_stream = text_to_phoneme_stream(query)
query_ngrams = make_phoneme_ngrams(query_stream, n=N)
query_vec = build_tf_vector(query_ngrams)

print("\n=== Debug: Example phonemes / ngrams ===")
print("Query phoneme stream (first 30):", query_stream[:30])
print("Query ngrams (first 10):", query_ngrams[:10])


# -------------------------
# D. Cosine similarity
# -------------------------
scores = []
for name, vec in doc_vectors.items():
    score = cosine_similarity_counter(query_vec, vec)
    scores.append((name, score))

scores_sorted = sorted(scores, key=lambda x: x[1], reverse=True)

df = pd.DataFrame(scores_sorted, columns=["Document", "CosineSimilarity"])
df["Rank"] = range(1, len(df) + 1)

print("\n=== Results Table ===")
display(df)


# -------------------------
# E. Visualization
# -------------------------
plt.figure()
plt.bar(df["Document"], df["CosineSimilarity"])
plt.title("Cosine Similarity: Query vs Documents (phoneme-3grams)")
plt.xlabel("Document")
plt.ylabel("Cosine Similarity")
plt.show()

best_doc = df.iloc[0]["Document"]
print(f"\nConclusion: The query is closest to '{best_doc}' based on phoneme-3gram cosine similarity.")

